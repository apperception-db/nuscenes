{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from utils.data_dirs import data_dirs\n",
    "from utils.filter_road import filter_road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa28c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data_dirs()\n",
    "print(d.raw_road)\n",
    "print(d.processed_road)\n",
    "print(d.raw_map)\n",
    "print(d.processed_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_expansion = os.path.join(d.raw_map, 'expansion')\n",
    "processed_expansion = os.path.join(d.processed_map, 'expansion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ad325",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokens = []\n",
    "for e in os.listdir(raw_expansion):\n",
    "    with open(os.path.join(raw_expansion, e), \"r\") as f:\n",
    "        e_json = json.load(f)\n",
    "    \n",
    "    tokens: \"Set[str]\" = set()\n",
    "        \n",
    "    for k, value in e_json.items():\n",
    "        if type(value) == list:\n",
    "            tokens.update({v[\"token\"] for v in value if type(v) == dict})\n",
    "        elif type(value) == dict:\n",
    "            tokens.update(value.keys())\n",
    "    \n",
    "    if not os.path.exists(processed_expansion):\n",
    "        os.makedirs(processed_expansion)\n",
    "    \n",
    "    with open(os.path.join(processed_expansion, e[:-len(\".json\")] + \"-tokens.json\"), \"w\") as f:\n",
    "        json.dump([*tokens], f)\n",
    "    \n",
    "    _tokens.append(tokens)\n",
    "\n",
    "for t1 in _tokens:\n",
    "    for t2 in _tokens:\n",
    "        if t1 == t2: continue\n",
    "        print(t1 & t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35960959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens_f in os.listdir(processed_expansion):\n",
    "    with open(os.path.join(processed_expansion, tokens_f), \"r\") as f:\n",
    "        tokens = {*json.load(f)}\n",
    "    \n",
    "    region = tokens_f[:-len(\"-tokens.json\")]\n",
    "    print(region)\n",
    "    filtered = filter_road(d.raw_road, tokens)\n",
    "    for k, v in filtered.items():\n",
    "        print(k, len(v))\n",
    "        base = os.path.join(d.processed_road, region)\n",
    "        if not os.path.exists(base):\n",
    "            os.makedirs(base)\n",
    "        with open(os.path.join(base, k + \".json\"), \"w\") as f:\n",
    "            json.dump(v, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3517e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7f19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
