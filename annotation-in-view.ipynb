{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pyquaternion import Quaternion\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data_dirs import data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.environ['NUSCENES_RAW_DATA']\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c846568",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir, output_dir, folder, EXPERIMENT_DATA, suffix, *_ = data_dirs(False)\n",
    "print(base_dir)\n",
    "print(output_dir)\n",
    "print(folder)\n",
    "print(EXPERIMENT_DATA)\n",
    "print(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = os.path.join(base_dir, folder)\n",
    "metadata_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filenames = os.listdir(metadata_dir)\n",
    "print(\"\\n\".join(metadata_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff836fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(output_dir, 'annotation.pickle'), 'rb') as f:\n",
    "#     raw_annotations = pickle.load(f).to_dict('records')\n",
    "raw_annotations = pd.read_pickle(os.path.join(output_dir, 'annotation.pkl')).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe26e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(output_dir, 'sample_data.pickle'), 'rb') as f:\n",
    "#     raw_sample_data = pickle.load(f).to_dict('records')\n",
    "raw_sample_data = pd.read_pickle(os.path.join(output_dir, 'sample_data.pkl')).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42322ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e529c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map from annotation token -> annotation\n",
    "annotation_map = {\n",
    "    a['token']: a\n",
    "    for a\n",
    "    in raw_annotations\n",
    "}\n",
    "assert len(annotation_map) == len(raw_annotations), (len(annotation_map), len(raw_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03842691",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map from sample data token (camera config token) -> sample data\n",
    "sample_data_map = {\n",
    "    sd['token']: sd\n",
    "    for sd\n",
    "    in raw_sample_data\n",
    "}\n",
    "assert len(sample_data_map) == len(raw_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in annotation_map.values():\n",
    "    for sdt in a['sample_data_tokens']:\n",
    "        assert sample_data_map[sdt]['sample_token'] == a['sample_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([sd for sd in raw_sample_data if sd['is_key_frame']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_token_to_annotation_map = {}\n",
    "# for a in raw_annotations:\n",
    "#     sample_token = a['sample_token']\n",
    "#     if sample_token not in annotation_map:\n",
    "#         sample_token_to_annotation_map[sample_token] = []\n",
    "#     sample_token_to_annotation_map[sample_token].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenes = {}\n",
    "# for sd in raw_sample_data:\n",
    "#     scene_name = sd['scene_name']\n",
    "#     if scene_name not in scenes:\n",
    "#         scenes[scene_name] = {}\n",
    "#     scene = scenes[scene_name]\n",
    "\n",
    "#     sample_token = sd['sample_token']\n",
    "#     if sample_token not in scene:\n",
    "#         scene[sample_token] = []\n",
    "#     scene[sample_token].append(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [*scenes.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6416bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [*scenes['scene-0061'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d054c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(scenes['scene-0061']['378a3a3e9af346308ab9dff8ced46d9c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find if each scene / camera has its key fame as its closest to the sample\n",
    "# closest_frame = {}\n",
    "# for scene_name, scene in scenes.items():\n",
    "#     for sample_token, sample in scene.items():\n",
    "#         camera = {}\n",
    "#         for s in sample:\n",
    "#             if s['channel'] not in camera:\n",
    "#                 camera[s['channel']] = []\n",
    "#             camera[s['channel']].append((\n",
    "#                 s['is_key_frame'],\n",
    "#                 s['timestamp'],\n",
    "#                 s['sample_timestamp'],\n",
    "#             ))\n",
    "        \n",
    "#         for c_name, _sample_data in camera.items():\n",
    "#             best_is_key_frame, best_timestamp, best_timestamp_diff = None, None, None\n",
    "#             for is_key_frame, timestamp, sample_timestamp in _sample_data:\n",
    "#                 timestamp_diff = sample_timestamp - timestamp\n",
    "#                 if best_timestamp_diff is None or abs(best_timestamp_diff) > abs(timestamp_diff):\n",
    "#                     best_is_key_frame, best_timestamp, best_timestamp_diff = is_key_frame, timestamp, timestamp_diff\n",
    "#             key = f'{sample_token}-{c_name}'\n",
    "#             assert key not in closest_frame\n",
    "#             closest_frame[key] = (best_is_key_frame, best_timestamp, best_timestamp_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [cf for cf in closest_frame.values() if not cf[0]]\n",
    "# # This filter is empty -> All the key frames are the one that is closest to the sample timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ce764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max([(cf[2]) for cf in closest_frame.values()]) / 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3aed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def world2pixel(annotation, sample_data):\n",
    "    ct = np.array(sample_data['camera_translation'])\n",
    "    cr = Quaternion(sample_data['camera_rotation'])\n",
    "    ci = np.array(sample_data['camera_intrinsic'])\n",
    "    at = np.array(annotation['translation'])\n",
    "\n",
    "    offset = (at - ct) # .reshape((3, 1))\n",
    "#     point_from_camera = np.dot(cr.unit.inverse.rotation_matrix, offset)\n",
    "    point_from_camera = cr.inverse.rotate(offset).reshape((3, 1))\n",
    "    if point_from_camera[2] < 0:\n",
    "        return np.array([-1, -1, 0])\n",
    "    assert point_from_camera.shape == (3, 1)\n",
    "    point2d = np.dot(ci, point_from_camera)\n",
    "    assert point2d.shape == (3,1)\n",
    "\n",
    "    return (point2d / point2d[2:3]).reshape((3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_view(annotation: \"dict[str, Any]\"):\n",
    "    def fn(sample_data_token: \"str\"):\n",
    "        sample_data = sample_data_map[sample_data_token]\n",
    "        point2d = world2pixel(annotation, sample_data)\n",
    "        x, y, _ = point2d\n",
    "        \n",
    "        _, _, _z = (Quaternion(sample_data['camera_rotation'])\n",
    "            .inverse\n",
    "            .rotate(np.array(annotation['translation']) - np.array(sample_data['camera_translation']))\n",
    "        )\n",
    "        return (0 <= x < 1600) and (0 <= y < 900) and _z > 0\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_view = []\n",
    "def split(a):\n",
    "    in_view_a = in_view(a)\n",
    "    sample_data_tokens = [*filter(in_view_a, a['sample_data_tokens'])]\n",
    "    channels = [sample_data_map[sdt]['channel'] for sdt in sample_data_tokens]\n",
    "#     assert len(sample_data_tokens) > 0\n",
    "    if len(sample_data_tokens) <= 0:\n",
    "        not_in_view.append(a)\n",
    "    return {\n",
    "        **a,\n",
    "        'sample_data_tokens': sample_data_tokens,\n",
    "        'out_of_view_sample_data_tokens': [*filter(lambda x : not in_view_a(x), a['sample_data_tokens'])],\n",
    "        'channels': channels\n",
    "    }\n",
    "output_annotations = [\n",
    "    split(a)\n",
    "    for a\n",
    "    in tqdm(raw_annotations)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57873dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_in_view), len(output_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in not_in_view if a['category'] == 'vehicle.car'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb191b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_objects = set(a['instance_token'] for a in not_in_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f572c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(a['category'] for a in not_in_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ed4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_to_annotations = {}\n",
    "sample_data_to_out_of_view_annotations = {}\n",
    "for o in output_annotations:\n",
    "    for sdt in o['sample_data_tokens']:\n",
    "        if sdt not in sample_data_to_annotations:\n",
    "            sample_data_to_annotations[sdt] = []\n",
    "        sample_data_to_annotations[sdt].append(o)\n",
    "    for sdt in o['out_of_view_sample_data_tokens']:\n",
    "        if sdt not in sample_data_to_out_of_view_annotations:\n",
    "            sample_data_to_out_of_view_annotations[sdt] = []\n",
    "        sample_data_to_out_of_view_annotations[sdt].append(o)\n",
    "print(len(sample_data_to_annotations))\n",
    "print(len(sample_data_to_out_of_view_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf885f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = {}\n",
    "for sd in raw_sample_data:\n",
    "    scene_name = sd['scene_name']\n",
    "    if scene_name not in scenes:\n",
    "        scenes[scene_name] = {}\n",
    "    scene = scenes[scene_name]\n",
    "    \n",
    "    channel = sd['channel']\n",
    "    if channel not in scene:\n",
    "        scene[channel] = []\n",
    "    scene[channel].append(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcecf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_eye_view(annotation, sample_data):\n",
    "    ct = np.array(sample_data['ego_translation'])\n",
    "    cr = Quaternion(sample_data['ego_rotation'])\n",
    "    at = np.array(annotation['translation'])\n",
    "    \n",
    "    offset = (at - ct)\n",
    "    point_from_ego = cr.inverse.rotate(offset)\n",
    "    return point_from_ego\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19764495",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_lines = [\n",
    "    [0, 1],\n",
    "    [0, 2],\n",
    "    [0, 4],\n",
    "    [1, 5],\n",
    "    [1, 3],\n",
    "    [2, 3],\n",
    "    [2, 6],\n",
    "    [3, 7],\n",
    "    [4, 5],\n",
    "    [4, 6],\n",
    "    [5, 7],\n",
    "    [6, 7],\n",
    "    [4, 7],\n",
    "    [5, 6],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def annotate_videos():\n",
    "#     shutil.rmtree('./output-videos')\n",
    "#     os.mkdir('./output-videos')\n",
    "    try:\n",
    "        os.mkdir(os.path.join(output_dir, 'annotated-videos'))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    width = 1600\n",
    "    height = 900\n",
    "\n",
    "    mapx = 1400\n",
    "    mapy = 200\n",
    "\n",
    "    for scenename, scene in scenes.items():\n",
    "        for channel, sds in scene.items():\n",
    "            frames = sorted(sds, key=lambda x: x['timestamp'])\n",
    "            filename = f'annotated-{scenename}-{channel}.mp4'\n",
    "            print(filename)\n",
    "\n",
    "            out = cv2.VideoWriter(\n",
    "                os.path.join(output_dir, 'annotated-videos', filename),\n",
    "                cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                10,\n",
    "                (width, height)\n",
    "            )\n",
    "\n",
    "            for frame in tqdm(frames):\n",
    "                if not frame['is_key_frame']:\n",
    "                    continue\n",
    "                imagefile = frame['filename']\n",
    "                img = cv2.imread(os.path.join(base_dir, imagefile))\n",
    "\n",
    "                sample_data_token = frame['token']\n",
    "                sd = sample_data_map[sample_data_token]\n",
    "\n",
    "                # Annotations BBox -> pixel\n",
    "                for a in sample_data_to_annotations.get(sample_data_token, []):\n",
    "                    if not in_view(a)(sample_data_token):\n",
    "                        raise Exception(a)\n",
    "\n",
    "                    size = (a['size'][1], a['size'][0], a['size'][2])\n",
    "                    _x0, _y0, _z0 = - (np.array(size) / 2)\n",
    "                    _x1, _y1, _z1 =   (np.array(size) / 2)\n",
    "                    _xs = [_x0, _x1]\n",
    "                    _ys = [_y0, _y1]\n",
    "                    _zs = [_z0, _z1]\n",
    "\n",
    "                    points = []\n",
    "                    for _x in _xs:\n",
    "                        for _y in _ys:\n",
    "                            for _z in _zs:\n",
    "                                _p = Quaternion(a['rotation']).rotate(np.array([_x, _y, _z]))\n",
    "                                p = world2pixel({\n",
    "                                    'translation': _p + a['translation'],\n",
    "                                    'category': a['category'],\n",
    "                                }, sd)[:2]\n",
    "\n",
    "                                points.append(p)\n",
    "\n",
    "                    if a['category'].startswith('vehicle'):\n",
    "                        color = (255, 0, 0)\n",
    "                    else:\n",
    "                        color = (0, 0, 255)\n",
    "                    for _p0, _p1 in bbox_lines:\n",
    "                        x0, y0 = points[_p0].astype(int)\n",
    "                        x1, y1 = points[_p1].astype(int)\n",
    "                        img = cv2.line(img, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "                # Plot All Annotations\n",
    "                for a in sample_data_to_annotations.get(sample_data_token, []) + sample_data_to_out_of_view_annotations.get(sample_data_token, []):\n",
    "                    white = False\n",
    "                    if not in_view(a)(sample_data_token):\n",
    "                        white = True\n",
    "\n",
    "                    point = bird_eye_view(a, sd)\n",
    "                    x, y, _ = (point * 3).astype(int)\n",
    "                    x += mapx\n",
    "                    y += mapy\n",
    "                    minx = max(0, min(1599, x - 1))\n",
    "                    miny = 899 - max(0, min(899, y + 1))\n",
    "                    maxx = max(0, min(1599, x + 1))\n",
    "                    maxy = 899 - max(0, min(899, y - 1))\n",
    "                    if white:\n",
    "                        img[miny:maxy, minx:maxx, 0] = 255\n",
    "                        img[miny:maxy, minx:maxx, 1] = 255\n",
    "                        img[miny:maxy, minx:maxx, 2] = 255\n",
    "                    elif a['category'].startswith('vehicle'):\n",
    "                        img[miny:maxy, minx:maxx, 0] = 255\n",
    "                        img[miny:maxy, minx:maxx, 1] = 0\n",
    "                        img[miny:maxy, minx:maxx, 2] = 0\n",
    "                    else:\n",
    "                        img[miny:maxy, minx:maxx, 0] = 0\n",
    "                        img[miny:maxy, minx:maxx, 1] = 0\n",
    "                        img[miny:maxy, minx:maxx, 2] = 255\n",
    "\n",
    "                # Plot Camera View Lines\n",
    "                for x, y in [(0, 0), (width, height), (width, 0), (0, height)]:\n",
    "                    [[fx, _, cx], [_, fy, cy], [_, _, s]] = sd['camera_intrinsic']\n",
    "                    _z = 1000\n",
    "                    _x = (s * x - cx) * _z / fx\n",
    "                    _y = (s * y - cy) * _z / fy\n",
    "\n",
    "                    xx, yy, _ = (Quaternion(sd['ego_rotation']).inverse.rotate(Quaternion(sd['camera_rotation']).rotate(np.array([_x, _y, _z]))) * 3).astype(int)\n",
    "\n",
    "                    xx += mapx\n",
    "                    yy += mapy\n",
    "\n",
    "                    origin = (mapx, 899 - mapy)\n",
    "\n",
    "                    img = cv2.line(img, origin, (xx, 899 - yy), (225, 225, 225), 2)\n",
    "\n",
    "                # Plot Ego Position\n",
    "                x = mapx\n",
    "                y = mapy\n",
    "                minx = max(0, min(1599, x - 1))\n",
    "                miny = 899 - max(0, min(899, y + 1))\n",
    "                maxx = max(0, min(1599, x + 1))\n",
    "                maxy = 899 - max(0, min(899, y - 1))\n",
    "\n",
    "                img[miny:maxy, minx:maxx, 0] = 0\n",
    "                img[miny:maxy, minx:maxx, 1] = 255\n",
    "                img[miny:maxy, minx:maxx, 2] = 0\n",
    "\n",
    "\n",
    "                # Plot Camera Position\n",
    "                ct = np.array(sd['ego_translation'])\n",
    "                cr = Quaternion(sd['ego_rotation'])\n",
    "                at = np.array(sd['camera_translation'])\n",
    "\n",
    "                offset = (at - ct)\n",
    "                x, y, _ = (cr.inverse.rotate(offset) * 3).astype(int)\n",
    "                x += mapx\n",
    "                y += mapy\n",
    "                minx = max(0, min(1599, x - 1))\n",
    "                miny = 899 - max(0, min(899, y + 1))\n",
    "                maxx = max(0, min(1599, x + 1))\n",
    "                maxy = 899 - max(0, min(899, y - 2))\n",
    "                img[miny:maxy, minx:maxx, 0] = 255\n",
    "                img[miny:maxy, minx:maxx, 1] = 0\n",
    "                img[miny:maxy, minx:maxx, 2] = 255\n",
    "\n",
    "                for _ in range(5):\n",
    "                    out.write(img)\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "annotate_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f31ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(output_dir, 'partitioned_annotation.pickle'), 'wb') as f:\n",
    "#     pickle.dump(pd.DataFrame.from_dict(output_annotations), f)\n",
    "df_output_annotations = pd.DataFrame.from_dict(output_annotations)\n",
    "df_output_annotations.to_pickle(os.path.join(output_dir, 'annotation_partitioned.pkl'))\n",
    "#     raw_annotations = pickle.load(f).to_dict('records')\n",
    "\n",
    "df_output_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_split = {}\n",
    "\n",
    "for scene_name, scene in scenes.items():\n",
    "    for camera_name, camera_configs in scene.items():\n",
    "        print(scene_name, camera_name)\n",
    "        key = scene_name + '_' + camera_name\n",
    "        anns = []\n",
    "        for config in camera_configs:\n",
    "            token = config['token']\n",
    "            if not config['is_key_frame']:\n",
    "                continue\n",
    "            if token not in sample_data_to_annotations:\n",
    "                print(token, token in sample_data_to_out_of_view_annotations)\n",
    "                continue\n",
    "            anns.extend((a, config) for a in sample_data_to_annotations[token])\n",
    "        def format_data(d):\n",
    "            a, config = d\n",
    "            # TODO: config is incorrect\n",
    "            _d = {**a, 'sample_data_token': config['token'], 'timestamp': config['timestamp']}\n",
    "            del _d['sample_token']\n",
    "            del _d['heading']\n",
    "            del _d['sample_data_tokens']\n",
    "            del _d['out_of_view_sample_data_tokens']\n",
    "            return _d\n",
    "        ground_truth_split[key] = [c['token'] for c in camera_configs], [*map(format_data, anns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2957134",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(key, len(val)) for key, val in ground_truth_split.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(output_dir, 'annotation_splitted.json'), 'w') as f:\n",
    "    json.dump(ground_truth_split, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43905fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94eec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcccab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf6f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (apperception)",
   "language": "python",
   "name": "apperception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
